{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# íŒ¨í‚¤ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from eunjeon import Mecab\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abuse_process_log_20220106.csv', 'apt_review_20220106.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Data/\"\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ë°ì´í„° ë¡œë”©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¦¬ë·°, ì²˜ë¦¬ë‚´ì—­ ë¡œê·¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hgnn = pd.read_csv(path + \"apt_review_20220106.csv\", encoding=\"UTF-8\")\n",
    "data_log = pd.read_csv(path + 'abuse_process_log_20220106.csv', encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¦¬ë·° ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ì²˜ë¦¬ë‚´ì—­ ë°ì´í„° ê°€ê³µ\n",
    "data_log = data_log[(data_log[\"type\"]==1)&(data_log[\"comment_id\"].isnull())] # Type == 1 : ì•„íŒŒíŠ¸ ë¦¬ë·°\n",
    "data_log = data_log[~((data_log[\"reason\"].str.contains(\"ë¬´íš¨\"))|(data_log[\"reason\"].str.contains(\"ë³µì›\")))]\n",
    "data_log = data_log[[\"review_id\", \"reason\"]].dropna().drop_duplicates(\"review_id\")\n",
    "\n",
    "# ë³‘í•©\n",
    "data_hgnn = data_hgnn[[\"id\", \"content\", \"is_blocked\", \"is_deleted\", \"is_blinded\"]]\n",
    "data = pd.merge(data_hgnn, data_log.rename(columns={\"review_id\":\"id\"}), on=\"id\", how=\"left\")\n",
    "\n",
    "# í•„í„°ë§\n",
    "data = data[~((data[\"is_deleted\"]==1)&(data[\"is_blocked\"]!=1)&(data[\"is_blinded\"]!=1))] # ìì§„ì‚­ì œí•œ ë°ì´í„°\n",
    "data = data[~data[\"content\"].isnull()] # ë‚´ìš©ì´ ê¸°ì¬ë˜ì§€ ì•Šì€ ë°ì´í„°\n",
    "data = data[data[\"content\"].str.len() > 20] # ìµœì†Œ 20ì ì´ìƒ ë¦¬ë·°\n",
    "\n",
    "# ìŠ¤íŒ¸ ê¸°ì¤€: is_blocked = 1ì´ê±°ë‚˜, ì²˜ë¦¬ì‚¬ìœ ê°€ ê¸°ì¬ëœ ë°ì´í„°\n",
    "data[\"is_spam\"] = np.where((data[\"is_blocked\"]==1)|(~data[\"reason\"].isnull()), 1, 0)\n",
    "\n",
    "# ê° ë¬¸ì¥ë³„, 1íšŒ ì´ìƒ ìŠ¤íŒ¸ ì²˜ë¦¬ëœ ë¬¸ì¥ì€ is_spamì—ì„œ 1, ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬ (ì™„ì „ ì¤‘ë³µë¬¸ì¥ ì œê±°)\n",
    "data_input = data.groupby(\"content\").sum()[[\"is_spam\"]].reset_index()\n",
    "data_input[\"is_spam\"] = np.where(data_input[\"is_spam\"] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í‚¤ì›Œë“œ í˜•íƒœì†Œ ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b099bbf65d634a4aa618ef50484399ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1993214.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tagger = Mecab()\n",
    "morphs = list()\n",
    "for i in tqdm(range(len(data_input))):\n",
    "    corpus = data_input[\"content\"].iloc[i]\n",
    "    try:\n",
    "        keywords = tagger.morphs(corpus.upper())\n",
    "        morphs.append([keywords])\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    \n",
    "    except:\n",
    "        morphs.append([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í˜•íƒœì†Œ ë‹¨ìœ„ë¡œ ë„ì–´ì¨ì„œ ì¬êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = pd.concat([pd.DataFrame(morphs)[0], data_input[\"is_spam\"].reset_index(drop=True)], axis=1).rename(columns={0:\"content\"}).dropna()\n",
    "data_input[\"content\"] = data_input[\"content\"].apply(lambda row: \" \".join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í›„ì²˜ë¦¬ (`zero with space` ì‚­ì œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input[\"content\"] = data_input[\"content\"].str.replace(\"\\u200b\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\b ì§€ì‹ ì´ ì¼ì • ìˆ˜ì¤€ ì´ìƒ ì´ ë©° , ë‹¤ì–‘ í•œ í™œë™ ê²½í—˜ ì´ ìˆ ìœ¼ì‹  ë¶„ ë“¤ ì´ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ëª©í¬ , ë‚´í•­ , ë‚¨í•­ ë¶í•­ ì„œë‚¨ê¶Œ ê²½ì œ íŠ¹í™” í•­ë§Œ ìœ¼ë¡œ ê°œë°œ ì¶”ì§„ HTTP : /...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë°•ìƒëˆ ì²œì•ˆì‹œì¥ íŠ¹ë³„ ëŒ€ë‹´ â€¦ ì¡°ì • ì§€ì—­ í•´ì œ ê±´ ì˜ ì‹œì‚¬ HTTPS : / / B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë°•ìƒëˆ ì²œì•ˆì‹œì¥ íŠ¹ë³„ ëŒ€ë‹´ â€¦ ì¡°ì • ì§€ì—­ í•´ì œ ê±´ ì˜ ì‹œì‚¬ HTTP : / / WW...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì„œì—° ì´ ìŒ í„° ë„ì„œê´€ í™”ì„±ì‹œ ì¥ì§€ë™ 115 - 1 ëŒ€ì§€ë©´ì  : 3 , 250 M ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993209</th>\n",
       "      <td>ğŸ¤¥ ğŸ¤ ğŸ¤ ğŸ˜¯ ğŸ¤¢ ğŸ˜¯ ğŸ‘¹ ğŸ˜¶ ğŸ‘¿ ğŸ˜ˆ ğŸ¤« ğŸ¤•ğŸ¤¢ğŸƒğŸ¤•ğŸ˜ºğŸ¤¢ğŸ¤¢ğŸ§ğŸ´ğŸ™ˆğŸ¦‡ğŸğŸµğŸ¦—ğŸ¸ğŸª²ğŸ¦‹ğŸ™‰ğŸ®ğŸœğŸ¦‹ğŸ¦ğŸ›ğŸ™‰ğŸœ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993210</th>\n",
       "      <td>ğŸ¥ˆ ğŸ‡ ğŸ ğŸ ğŸ³ ğŸ‰ ğŸ† ğŸ§§ğŸ‰ğŸğŸˆğŸğŸ“ğŸ‘ğŸˆğŸ’ğŸ§§ğŸˆğŸ–ğŸ¥ˆğŸ«ğŸ¥ˆğŸ¥ˆğŸ¥ğŸ¥ˆğŸ€ğŸ¥ˆğŸ…ğŸ¥ˆğŸ‘ğŸ¥ˆğŸ– âš¾ ï¸ ğŸ‰ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993211</th>\n",
       "      <td>ğŸ¥¥ğŸ¥¦ğŸŒ½ğŸ¥”ğŸ¥–ğŸ§ˆğŸ—ğŸŸğŸ•ğŸ¦´ğŸ¦´ğŸ¥ğŸ¤¿ğŸ¤ºğŸ¥…ğŸ¤¾ğŸ½ â€â™‚ ï¸ ğŸ¤¼ ğŸª‚ ğŸ§¬ ğŸ› ğŸ©¸ ğŸª£ ğŸ©¸ ğŸ§¸ ğŸª† ğŸ•³ ğŸ›‹ ğŸ‡¬...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993212</th>\n",
       "      <td>ğŸ¥¬ ğŸ¥¦ ğŸ« ğŸ¥­ ğŸŒ ğŸ‹ğŸŠğŸğŸ«‘ğŸ¥ğŸ¥¨ğŸ¤ğŸ›–ğŸğŸğŸ§­ğŸŒğŸ§±ğŸ¢ğŸ¬ğŸ¯ğŸğŸ¥ğŸ‘ğŸ§¨ğŸğŸ¥‰ğŸ¾ğŸğŸ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993213</th>\n",
       "      <td>ğŸ«’ğŸ¥šğŸ…ğŸ¥–ğŸ§ˆğŸ—ğŸ§„ğŸ¥’ğŸŸğŸ¥’ğŸ¦´ğŸ¥“ğŸ¥“ğŸ›¹ğŸ›¼ğŸ¤¼ğŸ£ğŸªƒğŸ¤¾ğŸ½ â€â™‚ ï¸ ğŸ§¬ ğŸ› ğŸ›€ ğŸ¿ ğŸ— ğŸ§¸ ğŸ©¸ ğŸ–¼ ğŸ‡¬ ğŸ‡º ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1993212 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   content  is_spam\n",
       "0        \b ì§€ì‹ ì´ ì¼ì • ìˆ˜ì¤€ ì´ìƒ ì´ ë©° , ë‹¤ì–‘ í•œ í™œë™ ê²½í—˜ ì´ ìˆ ìœ¼ì‹  ë¶„ ë“¤ ì´ ...        0\n",
       "1        ëª©í¬ , ë‚´í•­ , ë‚¨í•­ ë¶í•­ ì„œë‚¨ê¶Œ ê²½ì œ íŠ¹í™” í•­ë§Œ ìœ¼ë¡œ ê°œë°œ ì¶”ì§„ HTTP : /...        0\n",
       "2        ë°•ìƒëˆ ì²œì•ˆì‹œì¥ íŠ¹ë³„ ëŒ€ë‹´ â€¦ ì¡°ì • ì§€ì—­ í•´ì œ ê±´ ì˜ ì‹œì‚¬ HTTPS : / / B...        0\n",
       "3        ë°•ìƒëˆ ì²œì•ˆì‹œì¥ íŠ¹ë³„ ëŒ€ë‹´ â€¦ ì¡°ì • ì§€ì—­ í•´ì œ ê±´ ì˜ ì‹œì‚¬ HTTP : / / WW...        0\n",
       "4        ì„œì—° ì´ ìŒ í„° ë„ì„œê´€ í™”ì„±ì‹œ ì¥ì§€ë™ 115 - 1 ëŒ€ì§€ë©´ì  : 3 , 250 M ...        0\n",
       "...                                                    ...      ...\n",
       "1993209    ğŸ¤¥ ğŸ¤ ğŸ¤ ğŸ˜¯ ğŸ¤¢ ğŸ˜¯ ğŸ‘¹ ğŸ˜¶ ğŸ‘¿ ğŸ˜ˆ ğŸ¤« ğŸ¤•ğŸ¤¢ğŸƒğŸ¤•ğŸ˜ºğŸ¤¢ğŸ¤¢ğŸ§ğŸ´ğŸ™ˆğŸ¦‡ğŸğŸµğŸ¦—ğŸ¸ğŸª²ğŸ¦‹ğŸ™‰ğŸ®ğŸœğŸ¦‹ğŸ¦ğŸ›ğŸ™‰ğŸœ        1\n",
       "1993210  ğŸ¥ˆ ğŸ‡ ğŸ ğŸ ğŸ³ ğŸ‰ ğŸ† ğŸ§§ğŸ‰ğŸğŸˆğŸğŸ“ğŸ‘ğŸˆğŸ’ğŸ§§ğŸˆğŸ–ğŸ¥ˆğŸ«ğŸ¥ˆğŸ¥ˆğŸ¥ğŸ¥ˆğŸ€ğŸ¥ˆğŸ…ğŸ¥ˆğŸ‘ğŸ¥ˆğŸ– âš¾ ï¸ ğŸ‰ ...        1\n",
       "1993211  ğŸ¥¥ğŸ¥¦ğŸŒ½ğŸ¥”ğŸ¥–ğŸ§ˆğŸ—ğŸŸğŸ•ğŸ¦´ğŸ¦´ğŸ¥ğŸ¤¿ğŸ¤ºğŸ¥…ğŸ¤¾ğŸ½ â€â™‚ ï¸ ğŸ¤¼ ğŸª‚ ğŸ§¬ ğŸ› ğŸ©¸ ğŸª£ ğŸ©¸ ğŸ§¸ ğŸª† ğŸ•³ ğŸ›‹ ğŸ‡¬...        1\n",
       "1993212                ğŸ¥¬ ğŸ¥¦ ğŸ« ğŸ¥­ ğŸŒ ğŸ‹ğŸŠğŸğŸ«‘ğŸ¥ğŸ¥¨ğŸ¤ğŸ›–ğŸğŸğŸ§­ğŸŒğŸ§±ğŸ¢ğŸ¬ğŸ¯ğŸğŸ¥ğŸ‘ğŸ§¨ğŸğŸ¥‰ğŸ¾ğŸğŸ        1\n",
       "1993213  ğŸ«’ğŸ¥šğŸ…ğŸ¥–ğŸ§ˆğŸ—ğŸ§„ğŸ¥’ğŸŸğŸ¥’ğŸ¦´ğŸ¥“ğŸ¥“ğŸ›¹ğŸ›¼ğŸ¤¼ğŸ£ğŸªƒğŸ¤¾ğŸ½ â€â™‚ ï¸ ğŸ§¬ ğŸ› ğŸ›€ ğŸ¿ ğŸ— ğŸ§¸ ğŸ©¸ ğŸ–¼ ğŸ‡¬ ğŸ‡º ...        1\n",
       "\n",
       "[1993212 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. í•™ìŠµìš© ë°ì´í„° ì„¸íŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X, y ì„¸íŒ…\n",
    "X = data_input[\"content\"]\n",
    "y = data_input[\"is_spam\"]\n",
    "\n",
    "# í•™ìŠµ-í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¨ì–´ì§‘í•© ì‚¬ì´ì¦ˆ: 156192\n",
      "ë¦¬ë·° ì‹œí€€ìŠ¤ ìµœëŒ€ ê¸¸ì´: 22771\n",
      "ë¦¬ë·° ì‹œí€€ìŠ¤ í‰ê·  ê¸¸ì´: 44.24576233452425\n",
      "í›ˆë ¨ ë°ì´í„°ì˜ í¬ê¸°(shape): (1594569, 512)\n"
     ]
    }
   ],
   "source": [
    "# ë¦¬ë·° ë¬¸ì¥ í† í°í™”\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_encoded = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "# ë‹¨ì–´ì§‘í•© ì´ í¬ê¸°\n",
    "word_to_index = tokenizer.word_index\n",
    "vocab_size = len(word_to_index) + 1\n",
    "print(f\"ë‹¨ì–´ì§‘í•© ì‚¬ì´ì¦ˆ: {vocab_size}\")\n",
    "print(f'ë¦¬ë·° ì‹œí€€ìŠ¤ ìµœëŒ€ ê¸¸ì´: {max(len(l) for l in X_train_encoded)}')\n",
    "print(f'ë¦¬ë·° ì‹œí€€ìŠ¤ í‰ê·  ê¸¸ì´: {(sum(map(len, X_train_encoded))/len(X_train_encoded))}')\n",
    "\n",
    "# í›ˆë ¨ ë°ì´í„° íŒ¨ë”©\n",
    "max_len = 512\n",
    "X_train_padded = pad_sequences(X_train_encoded, maxlen = max_len)\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°ì˜ í¬ê¸°(shape): {X_train_padded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ëª¨í˜• í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨í˜• êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          9996288   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 10,008,737\n",
      "Trainable params: 10,008,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 64))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2336/2336 [==============================] - 239s 102ms/step - loss: 0.0996 - acc: 0.9685 - val_loss: 0.0874 - val_acc: 0.9704\n",
      "Epoch 2/2\n",
      "2336/2336 [==============================] - 239s 103ms/step - loss: 0.0789 - acc: 0.9722 - val_loss: 0.0854 - val_acc: 0.9710\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_padded, y_train, epochs=2, batch_size=512, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í…ŒìŠ¤íŠ¸ ì •í™•ë„ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12458/12458 [==============================] - 172s 14ms/step - loss: 0.0849 - acc: 0.9713\n",
      "í…ŒìŠ¤íŠ¸ ì •í™•ë„: 0.9712600111961365\n"
     ]
    }
   ],
   "source": [
    "X_test_encoded = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_encoded, maxlen = max_len)\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {model.evaluate(X_test_padded, y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•™ìŠµëœ ëª¨ë¸ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(f\"Models/Spam_Classifier.h5\")\n",
    "with open(f'Models/Tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨í˜• ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f\"Models/Spam_Classifier.h5\")\n",
    "with open(f'Models/Tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separated(array):\n",
    "    return [\" \".join(tagger.morphs(array[i])) for i in range(len(array))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(array):\n",
    "    array = separated(list(array))\n",
    "    array = tokenizer.texts_to_sequences(array)\n",
    "    array = pad_sequences(array, maxlen = 512)\n",
    "    return model.predict(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í™•ë¥  ì˜ˆì¸¡\n",
    "data_test = pd.concat([X_test, y_test], axis=1)\n",
    "prob = predict(data_test[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜•íƒœì†Œ ë¶„ë¦¬ ì „ ì›ë³¸ ë°ì´í„° ë³µêµ¬\n",
    "data_test = pd.merge(data_test.reset_index().rename(columns={\"content\":\"content_edit\"}), \n",
    "                     data.groupby(\"content\").sum()[[\"is_spam\"]].reset_index().reset_index()[[\"index\", \"content\"]], \n",
    "                     on=\"index\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ë°ì´í„° ì •ë¦¬\n",
    "result = pd.concat([data_test, pd.DataFrame(prob, columns=[\"prob\"])], axis=1)[[\"content\", \"content_edit\", \"is_spam\", \"prob\"]]\n",
    "result[\"verdict\"] = np.where(result[\"prob\"] > 0.5, 1, 0)\n",
    "result[\"prob\"] *= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(\"ë¦¬ë·°ë³„ ìŠ¤íŒ¸ì„± ë¦¬ë·° ì˜ˆì¸¡ê²°ê³¼.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
